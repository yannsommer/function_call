{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# PDF RAG ç³»ç»Ÿ - ä½¿ç”¨ BGE-M3 Embedding æ¨¡å‹\n",
    "\n",
    "æœ¬ Notebook å±•ç¤ºå¦‚ä½•ä½¿ç”¨ XPULink å¹³å°æ‰˜ç®¡çš„ BGE-M3 Embedding æ¨¡å‹æ„å»ºä¸€ä¸ªåŸºäº PDF æ–‡æ¡£çš„ RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ç³»ç»Ÿã€‚\n",
    "\n",
    "## åŠŸèƒ½ç‰¹æ€§\n",
    "- åŠ è½½å’Œå¤„ç† PDF æ–‡æ¡£\n",
    "- ä½¿ç”¨ BGE-M3 Embedding æ¨¡å‹è¿›è¡Œæ–‡æ¡£å‘é‡åŒ–\n",
    "- æ„å»ºå‘é‡ç´¢å¼•å®ç°é«˜æ•ˆæ£€ç´¢\n",
    "- åŸºäºæ£€ç´¢ç»“æœç”Ÿæˆæ™ºèƒ½å›ç­”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## 1. ç¯å¢ƒé…ç½®å’Œä¾èµ–å®‰è£…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£…å¿…è¦çš„ä¾èµ–åŒ…\n",
    "!pip install llama-index-core llama-index-llms-openai python-dotenv pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from typing import List, Optional\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings\n",
    "from llama_index.core.embeddings import BaseEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "# æ£€æŸ¥ API Key\n",
    "if os.getenv('XPU_API_KEY'):\n",
    "    print(\"âœ… æ‰¾åˆ° XPU_API_KEY ç¯å¢ƒå˜é‡\")\n",
    "else:\n",
    "    raise ValueError(\"âŒ æœªæ‰¾åˆ° XPU_API_KEYã€‚è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®åå†è¿è¡Œæ­¤è„šæœ¬ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedding-class",
   "metadata": {},
   "source": [
    "## 2. å®šä¹‰ BGE-M3 Embedding ç±»\n",
    "\n",
    "BGE-M3 æ˜¯ä¸€ä¸ªå¼ºå¤§çš„å¤šè¯­è¨€ Embedding æ¨¡å‹ï¼Œæ”¯æŒä¸­è‹±æ–‡ç­‰å¤šç§è¯­è¨€ï¼Œç‰¹åˆ«é€‚åˆå¤„ç†ä¸­æ–‡æ–‡æ¡£ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bge-embedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BGEM3Embedding(BaseEmbedding):\n",
    "    \"\"\"BGE-M3 Embedding æ¨¡å‹å®ç°ï¼ˆåŸºäº OpenAI å…¼å®¹ APIï¼‰\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        api_base: str = \"https://xpulink.ai/v1\",\n",
    "        api_key: Optional[str] = None,\n",
    "        model: str = \"bge-m3\",\n",
    "        embed_batch_size: int = 10,\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        åˆå§‹åŒ– BGE-M3 Embedding æ¨¡å‹\n",
    "        \n",
    "        Args:\n",
    "            api_base: XPULink API åŸºç¡€åœ°å€\n",
    "            api_key: API å¯†é’¥ï¼ˆä»ç¯å¢ƒå˜é‡è·å–ï¼‰\n",
    "            model: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä¸º bge-m3\n",
    "            embed_batch_size: æ‰¹å¤„ç†å¤§å°\n",
    "        \"\"\"\n",
    "        self.api_base = api_base.rstrip('/')\n",
    "        self.api_key = api_key or os.getenv(\"XPU_API_KEY\")\n",
    "        self.model = model\n",
    "        self.embed_batch_size = embed_batch_size\n",
    "        \n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"éœ€è¦æä¾› API Key\")\n",
    "        \n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def _call_api(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"è°ƒç”¨ XPULink API è·å– embeddings\"\"\"\n",
    "        headers = {\n",
    "            'Authorization': f'Bearer {self.api_key}',\n",
    "            'Content-Type': 'application/json'\n",
    "        }\n",
    "        \n",
    "        data = {\n",
    "            'model': self.model,\n",
    "            'input': texts\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(\n",
    "                f\"{self.api_base}/embeddings\",\n",
    "                headers=headers,\n",
    "                json=data,\n",
    "                timeout=60\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            result = response.json()\n",
    "            if result.get('data'):\n",
    "                return [item['embedding'] for item in result['data']]\n",
    "            else:\n",
    "                raise Exception(f\"API è¿”å›æ ¼å¼é”™è¯¯: {result}\")\n",
    "                \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            raise Exception(f\"API è¯·æ±‚å¤±è´¥: {str(e)}\")\n",
    "    \n",
    "    def _get_query_embedding(self, query: str) -> List[float]:\n",
    "        \"\"\"è·å–å•ä¸ªæŸ¥è¯¢çš„ embedding\"\"\"\n",
    "        embeddings = self._call_api([query])\n",
    "        return embeddings[0] if embeddings else []\n",
    "    \n",
    "    def _get_text_embeddings(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"æ‰¹é‡è·å–æ–‡æœ¬çš„ embeddings\"\"\"\n",
    "        all_embeddings = []\n",
    "        \n",
    "        # åˆ†æ‰¹å¤„ç†\n",
    "        for i in range(0, len(texts), self.embed_batch_size):\n",
    "            batch = texts[i:i + self.embed_batch_size]\n",
    "            batch_embeddings = self._call_api(batch)\n",
    "            all_embeddings.extend(batch_embeddings)\n",
    "            \n",
    "            if i + self.embed_batch_size < len(texts):\n",
    "                print(f\"å·²å¤„ç† {i + len(batch)}/{len(texts)} ä¸ªæ–‡æœ¬ç‰‡æ®µ\")\n",
    "        \n",
    "        return all_embeddings\n",
    "    \n",
    "    async def _aget_query_embedding(self, query: str) -> List[float]:\n",
    "        \"\"\"å¼‚æ­¥è·å–æŸ¥è¯¢ embeddingï¼ˆå›é€€åˆ°åŒæ­¥æ–¹æ³•ï¼‰\"\"\"\n",
    "        return self._get_query_embedding(query)\n",
    "    \n",
    "    @property\n",
    "    def model_name(self) -> str:\n",
    "        return self.model\n",
    "\n",
    "print(\"âœ… BGE-M3 Embedding ç±»å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config",
   "metadata": {},
   "source": [
    "## 3. é…ç½® LlamaIndex Settings\n",
    "\n",
    "é…ç½®å…¨å±€çš„ Embedding æ¨¡å‹å’Œ LLMã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-settings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é…ç½® BGE-M3 Embedding æ¨¡å‹\n",
    "Settings.embed_model = BGEM3Embedding(\n",
    "    api_base=\"https://xpulink.ai/v1\",\n",
    "    model=\"bge-m3\",\n",
    "    embed_batch_size=10\n",
    ")\n",
    "\n",
    "# é…ç½® LLMï¼ˆç”¨äºç”Ÿæˆå›ç­”ï¼‰\n",
    "Settings.llm = OpenAI(\n",
    "    api_key=os.getenv(\"XPU_API_KEY\"),\n",
    "    api_base=\"https://www.xpulink.ai/v1\",\n",
    "    model=\"qwen3-32b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(\"âœ… LlamaIndex é…ç½®å®Œæˆ\")\n",
    "print(f\"  - Embedding æ¨¡å‹: {Settings.embed_model.model_name}\")\n",
    "print(f\"  - LLM æ¨¡å‹: {Settings.llm.model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-docs",
   "metadata": {},
   "source": [
    "## 4. åŠ è½½ PDF æ–‡æ¡£\n",
    "\n",
    "å°† PDF æ–‡ä»¶æ”¾åœ¨ `data/` ç›®å½•ä¸‹ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨åŠ è½½å¹¶å¤„ç†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-pdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®¾ç½®æ•°æ®ç›®å½•è·¯å¾„\n",
    "DATA_DIR = \"./data/\"\n",
    "\n",
    "# ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR)\n",
    "    print(f\"ğŸ“ å·²åˆ›å»ºæ•°æ®ç›®å½•: {DATA_DIR}\")\n",
    "    print(\"âš ï¸  è¯·å°† PDF æ–‡ä»¶æ”¾å…¥æ­¤ç›®å½•åé‡æ–°è¿è¡Œæ­¤å•å…ƒæ ¼\")\n",
    "else:\n",
    "    # åŠ è½½æ–‡æ¡£\n",
    "    try:\n",
    "        documents = SimpleDirectoryReader(\n",
    "            input_dir=DATA_DIR,\n",
    "            required_exts=[\".pdf\"]\n",
    "        ).load_data()\n",
    "        \n",
    "        if documents:\n",
    "            print(f\"âœ… æˆåŠŸåŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£ç‰‡æ®µ\")\n",
    "            print(f\"\\nğŸ“„ ç¬¬ä¸€ä¸ªæ–‡æ¡£ç‰‡æ®µé¢„è§ˆ:\")\n",
    "            print(f\"  - é•¿åº¦: {len(documents[0].text)} å­—ç¬¦\")\n",
    "            print(f\"  - å†…å®¹é¢„è§ˆ: {documents[0].text[:200]}...\")\n",
    "        else:\n",
    "            print(f\"âš ï¸  æœªåœ¨ {DATA_DIR} ç›®å½•ä¸­æ‰¾åˆ° PDF æ–‡ä»¶\")\n",
    "            print(\"è¯·æ·»åŠ  PDF æ–‡ä»¶åé‡æ–°è¿è¡Œæ­¤å•å…ƒæ ¼\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ åŠ è½½æ–‡æ¡£å¤±è´¥: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "build-index",
   "metadata": {},
   "source": [
    "## 5. æ„å»ºå‘é‡ç´¢å¼•\n",
    "\n",
    "ä½¿ç”¨ BGE-M3 æ¨¡å‹å¯¹æ–‡æ¡£è¿›è¡Œå‘é‡åŒ–ï¼Œå¹¶æ„å»ºç´¢å¼•ä»¥æ”¯æŒé«˜æ•ˆæ£€ç´¢ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-index",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'documents' in locals() and documents:\n",
    "    print(\"ğŸ”„ å¼€å§‹æ„å»ºå‘é‡ç´¢å¼•...\")\n",
    "    print(\"   è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´ï¼Œå–å†³äºæ–‡æ¡£å¤§å°\\n\")\n",
    "    \n",
    "    try:\n",
    "        # æ„å»ºå‘é‡ç´¢å¼•\n",
    "        index = VectorStoreIndex.from_documents(\n",
    "            documents,\n",
    "            show_progress=True\n",
    "        )\n",
    "        \n",
    "        print(\"\\nâœ… å‘é‡ç´¢å¼•æ„å»ºå®Œæˆï¼\")\n",
    "        print(\"   ç°åœ¨å¯ä»¥è¿›è¡Œæ–‡æ¡£æŸ¥è¯¢äº†\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ æ„å»ºç´¢å¼•å¤±è´¥: {str(e)}\")\n",
    "else:\n",
    "    print(\"âš ï¸  è¯·å…ˆè¿è¡Œä¸Šä¸€ä¸ªå•å…ƒæ ¼åŠ è½½æ–‡æ¡£\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "query",
   "metadata": {},
   "source": [
    "## 6. åˆ›å»ºæŸ¥è¯¢å¼•æ“\n",
    "\n",
    "åˆ›å»ºæŸ¥è¯¢å¼•æ“ï¼Œæ”¯æŒåŸºäºæ–‡æ¡£å†…å®¹çš„æ™ºèƒ½é—®ç­”ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-engine",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'index' in locals():\n",
    "    # åˆ›å»ºæŸ¥è¯¢å¼•æ“\n",
    "    query_engine = index.as_query_engine(\n",
    "        similarity_top_k=3,  # è¿”å›æœ€ç›¸ä¼¼çš„ 3 ä¸ªç‰‡æ®µ\n",
    "        response_mode=\"compact\"  # ä½¿ç”¨ç´§å‡‘æ¨¡å¼ç”Ÿæˆå›ç­”\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… æŸ¥è¯¢å¼•æ“åˆ›å»ºå®Œæˆ\")\n",
    "    print(\"\\nä½¿ç”¨æ–¹å¼:\")\n",
    "    print(\"  response = query_engine.query('ä½ çš„é—®é¢˜')\")\n",
    "    print(\"  print(response)\")\n",
    "else:\n",
    "    print(\"âš ï¸  è¯·å…ˆè¿è¡Œä¸Šä¸€ä¸ªå•å…ƒæ ¼æ„å»ºç´¢å¼•\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-queries",
   "metadata": {},
   "source": [
    "## 7. ç¤ºä¾‹æŸ¥è¯¢\n",
    "\n",
    "è¿è¡Œä¸€äº›ç¤ºä¾‹æŸ¥è¯¢æ¥æµ‹è¯• RAG ç³»ç»Ÿã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "query-example-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¤ºä¾‹æŸ¥è¯¢ 1\n",
    "if 'query_engine' in locals():\n",
    "    query = \"æ–‡æ¡£çš„ä¸»è¦å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ\"\n",
    "    print(f\"ğŸ” æŸ¥è¯¢: {query}\\n\")\n",
    "    \n",
    "    try:\n",
    "        response = query_engine.query(query)\n",
    "        print(\"ğŸ’¡ å›ç­”:\")\n",
    "        print(response)\n",
    "        \n",
    "        print(\"\\nğŸ“š ç›¸å…³æ–‡æ¡£ç‰‡æ®µ:\")\n",
    "        for i, node in enumerate(response.source_nodes, 1):\n",
    "            print(f\"\\n  ç‰‡æ®µ {i} (ç›¸ä¼¼åº¦: {node.score:.4f}):\")\n",
    "            print(f\"  {node.text[:200]}...\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ æŸ¥è¯¢å¤±è´¥: {str(e)}\")\n",
    "else:\n",
    "    print(\"âš ï¸  è¯·å…ˆåˆ›å»ºæŸ¥è¯¢å¼•æ“\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "query-example-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¤ºä¾‹æŸ¥è¯¢ 2 - è‡ªå®šä¹‰æŸ¥è¯¢\n",
    "if 'query_engine' in locals():\n",
    "    # ä¿®æ”¹è¿™é‡Œçš„æŸ¥è¯¢å†…å®¹\n",
    "    custom_query = \"è¯·æ€»ç»“æ–‡æ¡£ä¸­çš„å…³é”®è¦ç‚¹\"\n",
    "    \n",
    "    print(f\"ğŸ” æŸ¥è¯¢: {custom_query}\\n\")\n",
    "    \n",
    "    try:\n",
    "        response = query_engine.query(custom_query)\n",
    "        print(\"ğŸ’¡ å›ç­”:\")\n",
    "        print(response)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ æŸ¥è¯¢å¤±è´¥: {str(e)}\")\n",
    "else:\n",
    "    print(\"âš ï¸  è¯·å…ˆåˆ›å»ºæŸ¥è¯¢å¼•æ“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interactive",
   "metadata": {},
   "source": [
    "## 8. äº¤äº’å¼æŸ¥è¯¢\n",
    "\n",
    "åˆ›å»ºä¸€ä¸ªç®€å•çš„äº¤äº’å¼ç•Œé¢ï¼Œæ–¹ä¾¿è¿›è¡Œå¤šè½®æŸ¥è¯¢ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interactive-query",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_query():\n",
    "    \"\"\"äº¤äº’å¼æŸ¥è¯¢å‡½æ•°\"\"\"\n",
    "    if 'query_engine' not in locals() and 'query_engine' not in globals():\n",
    "        print(\"âš ï¸  è¯·å…ˆåˆ›å»ºæŸ¥è¯¢å¼•æ“\")\n",
    "        return\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"ğŸ“– PDF RAG äº¤äº’å¼æŸ¥è¯¢ç³»ç»Ÿ\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"è¾“å…¥ 'exit' æˆ– 'quit' é€€å‡º\\n\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"\\nğŸ” è¯·è¾“å…¥æ‚¨çš„é—®é¢˜: \").strip()\n",
    "            \n",
    "            if query.lower() in ['exit', 'quit', 'é€€å‡º']:\n",
    "                print(\"\\nğŸ‘‹ å†è§ï¼\")\n",
    "                break\n",
    "            \n",
    "            if not query:\n",
    "                continue\n",
    "            \n",
    "            print(\"\\nğŸ’­ æ€è€ƒä¸­...\\n\")\n",
    "            response = query_engine.query(query)\n",
    "            \n",
    "            print(\"ğŸ’¡ å›ç­”:\")\n",
    "            print(response)\n",
    "            print(\"\\n\" + \"-\"*50)\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\nğŸ‘‹ å†è§ï¼\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ æŸ¥è¯¢å‡ºé”™: {str(e)}\")\n",
    "\n",
    "# å–æ¶ˆæ³¨é‡Šä¸‹é¢è¿™è¡Œæ¥å¯åŠ¨äº¤äº’å¼æŸ¥è¯¢\n",
    "# interactive_query()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## æ€»ç»“\n",
    "\n",
    "æœ¬ Notebook å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ XPULink å¹³å°ä¸Šçš„ BGE-M3 Embedding æ¨¡å‹æ„å»ºä¸€ä¸ªå®Œæ•´çš„ PDF RAG ç³»ç»Ÿï¼š\n",
    "\n",
    "1. âœ… é…ç½®äº† BGE-M3 Embedding æ¨¡å‹\n",
    "2. âœ… åŠ è½½å’Œå¤„ç† PDF æ–‡æ¡£\n",
    "3. âœ… æ„å»ºäº†å‘é‡ç´¢å¼•\n",
    "4. âœ… å®ç°äº†æ™ºèƒ½æŸ¥è¯¢åŠŸèƒ½\n",
    "5. âœ… æä¾›äº†äº¤äº’å¼æŸ¥è¯¢ç•Œé¢\n",
    "\n",
    "### ä¸‹ä¸€æ­¥\n",
    "\n",
    "- å¯ä»¥å°è¯•ä¸åŒçš„ PDF æ–‡æ¡£\n",
    "- è°ƒæ•´ `similarity_top_k` å‚æ•°æ¥æ§åˆ¶æ£€ç´¢çš„æ–‡æ¡£æ•°é‡\n",
    "- ä¿®æ”¹ LLM çš„ `temperature` å‚æ•°æ¥æ§åˆ¶å›ç­”çš„åˆ›é€ æ€§\n",
    "- é›†æˆåˆ°å®é™…åº”ç”¨ä¸­\n",
    "\n",
    "### ç›¸å…³èµ„æº\n",
    "\n",
    "- [XPULink å®˜ç½‘](https://www.xpulink.ai)\n",
    "- [LlamaIndex æ–‡æ¡£](https://docs.llamaindex.ai/)\n",
    "- [BGE-M3 æ¨¡å‹ä»‹ç»](https://github.com/FlagOpen/FlagEmbedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
